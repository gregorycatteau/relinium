#!/usr/bin/env python3
"""
SSOT v1.0 - Script d'audit cryptographique
VÃ©rifie l'intÃ©gritÃ© de tous les livrables par comparaison des hashes SHA256
"""

import hashlib
import yaml
import os
import sys
from pathlib import Path
from datetime import datetime, timezone
from typing import Dict, List, Tuple, Any

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CONFIGURATION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

PROJECT_ROOT = Path(__file__).parent.parent
HASHES_FILE = PROJECT_ROOT / "docs/sprints/SSOT-v1.0/03-validation/SSOT_V1_HASHES.yaml"
REPORT_FILE = PROJECT_ROOT / "docs/sprints/SSOT-v1.0/02-evidence/S5_HASH_VERIFICATION_REPORT.txt"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# FONCTIONS UTILITAIRES
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def calculate_sha256(file_path: Path) -> str:
    """Calcule le hash SHA256 d'un fichier."""
    sha256_hash = hashlib.sha256()
    try:
        with open(file_path, "rb") as f:
            # Lecture par blocs de 64KB pour gÃ©rer les gros fichiers
            for byte_block in iter(lambda: f.read(65536), b""):
                sha256_hash.update(byte_block)
        return sha256_hash.hexdigest()
    except FileNotFoundError:
        return "FILE_NOT_FOUND"
    except Exception as e:
        return f"ERROR: {str(e)}"

def load_hashes_registry() -> Dict[str, Any]:
    """Charge le registre des hashes."""
    try:
        with open(HASHES_FILE, 'r', encoding='utf-8') as f:
            return yaml.safe_load(f)
    except Exception as e:
        print(f"âŒ Erreur lors de la lecture du registre des hashes: {e}")
        sys.exit(1)

def extract_deliverables(registry: Dict[str, Any]) -> List[Dict[str, Any]]:
    """Extrait tous les livrables du registre."""
    deliverables = []
    
    # S1 deliverables
    if 's1_deliverables' in registry:
        for item in registry['s1_deliverables']:
            if 'path' in item and 'hash' in item:
                deliverables.append({
                    'sprint': 'S1',
                    'name': item.get('name', 'Unknown'),
                    'path': item['path'],
                    'expected_hash': item['hash'],
                    'type': item.get('type', 'unknown')
                })
    
    # S2 deliverables
    if 's2_deliverables' in registry:
        for item in registry['s2_deliverables']:
            if 'path' in item and 'hash' in item:
                deliverables.append({
                    'sprint': 'S2',
                    'name': item.get('name', 'Unknown'),
                    'path': item['path'],
                    'expected_hash': item['hash'],
                    'type': item.get('type', 'unknown')
                })
    
    # S3 deliverables
    if 's3_deliverables' in registry:
        for item in registry['s3_deliverables']:
            if 'path' in item and 'hash' in item:
                deliverables.append({
                    'sprint': 'S3',
                    'name': item.get('name', 'Unknown'),
                    'path': item['path'],
                    'expected_hash': item['hash'],
                    'type': item.get('type', 'unknown')
                })
    
    # S4 deliverables
    if 's4_deliverables' in registry:
        for item in registry['s4_deliverables']:
            if 'path' in item and 'hash' in item:
                deliverables.append({
                    'sprint': 'S4',
                    'name': item.get('name', 'Unknown'),
                    'path': item['path'],
                    'expected_hash': item['hash'],
                    'type': item.get('type', 'unknown')
                })
    
    return deliverables

def verify_deliverables(deliverables: List[Dict[str, Any]]) -> Tuple[List[Dict], List[Dict], List[Dict]]:
    """
    VÃ©rifie tous les livrables.
    
    Returns:
        Tuple de (validÃ©s, divergents, fichiers manquants)
    """
    valid = []
    divergent = []
    missing = []
    
    for deliverable in deliverables:
        # Ignorer les fichiers avec des hashes spÃ©ciaux
        expected_hash = deliverable['expected_hash']
        if expected_hash in ['pending', 'self_reference', 'pending_hash']:
            continue
        
        file_path = PROJECT_ROOT / deliverable['path']
        actual_hash = calculate_sha256(file_path)
        
        if actual_hash == "FILE_NOT_FOUND":
            missing.append({
                **deliverable,
                'actual_hash': 'FILE_NOT_FOUND'
            })
        elif actual_hash.startswith("ERROR"):
            divergent.append({
                **deliverable,
                'actual_hash': actual_hash
            })
        elif actual_hash == expected_hash:
            valid.append({
                **deliverable,
                'actual_hash': actual_hash
            })
        else:
            divergent.append({
                **deliverable,
                'actual_hash': actual_hash
            })
    
    return valid, divergent, missing

def calculate_corpus_hash(valid_deliverables: List[Dict]) -> str:
    """
    Calcule le hash global du corpus en concatÃ©nant tous les hashes triÃ©s.
    """
    # Extraire tous les hashes et les trier
    hashes = sorted([d['expected_hash'] for d in valid_deliverables])
    
    # ConcatÃ©ner et hasher
    concatenated = ''.join(hashes)
    corpus_hash = hashlib.sha256(concatenated.encode()).hexdigest()
    
    return corpus_hash

def generate_report(valid: List[Dict], divergent: List[Dict], missing: List[Dict], 
                   corpus_hash: str, execution_time: float) -> str:
    """GÃ©nÃ¨re le rapport de vÃ©rification."""
    
    report_lines = [
        "â•" * 80,
        "SSOT v1.0 - RAPPORT DE VÃ‰RIFICATION DES HASHES",
        "â•" * 80,
        "",
        f"Date de gÃ©nÃ©ration : {datetime.now(timezone.utc).isoformat()}",
        f"Fichier source : {HASHES_FILE.relative_to(PROJECT_ROOT)}",
        f"Temps d'exÃ©cution : {execution_time:.3f} secondes",
        "",
        "â”€" * 80,
        "RÃ‰SUMÃ‰",
        "â”€" * 80,
        "",
        f"Total de fichiers auditÃ©s  : {len(valid) + len(divergent) + len(missing)}",
        f"âœ… Hashes valides           : {len(valid)}",
        f"âŒ Hashes divergents        : {len(divergent)}",
        f"âš ï¸  Fichiers manquants      : {len(missing)}",
        "",
        f"ğŸ” Hash global du corpus   : {corpus_hash}",
        "",
    ]
    
    # Section des fichiers valides
    if valid:
        report_lines.extend([
            "â”€" * 80,
            "FICHIERS VALIDES",
            "â”€" * 80,
            ""
        ])
        
        by_sprint = {}
        for item in valid:
            sprint = item['sprint']
            if sprint not in by_sprint:
                by_sprint[sprint] = []
            by_sprint[sprint].append(item)
        
        for sprint in sorted(by_sprint.keys()):
            report_lines.append(f"## {sprint} - {len(by_sprint[sprint])} fichier(s)")
            report_lines.append("")
            for item in by_sprint[sprint]:
                report_lines.extend([
                    f"  Nom   : {item['name']}",
                    f"  Path  : {item['path']}",
                    f"  Hash  : {item['expected_hash']}",
                    f"  Type  : {item['type']}",
                    f"  âœ… VALIDE",
                    ""
                ])
    
    # Section des divergences
    if divergent:
        report_lines.extend([
            "â”€" * 80,
            "âš ï¸  DIVERGENCES DÃ‰TECTÃ‰ES",
            "â”€" * 80,
            ""
        ])
        
        for item in divergent:
            report_lines.extend([
                f"  Nom          : {item['name']}",
                f"  Path         : {item['path']}",
                f"  Hash attendu : {item['expected_hash']}",
                f"  Hash actuel  : {item['actual_hash']}",
                f"  âŒ DIVERGENCE",
                ""
            ])
    
    # Section des fichiers manquants
    if missing:
        report_lines.extend([
            "â”€" * 80,
            "âš ï¸  FICHIERS MANQUANTS",
            "â”€" * 80,
            ""
        ])
        
        for item in missing:
            report_lines.extend([
                f"  Nom  : {item['name']}",
                f"  Path : {item['path']}",
                f"  âš ï¸  FICHIER NON TROUVÃ‰",
                ""
            ])
    
    # Conclusion
    report_lines.extend([
        "â”€" * 80,
        "CONCLUSION",
        "â”€" * 80,
        ""
    ])
    
    if not divergent and not missing:
        report_lines.extend([
            "âœ… AUDIT RÃ‰USSI",
            "",
            "Tous les fichiers du SSOT v1.0 ont Ã©tÃ© vÃ©rifiÃ©s avec succÃ¨s.",
            "Aucune divergence cryptographique dÃ©tectÃ©e.",
            "Le corpus est certifiÃ© complet et intÃ¨gre.",
            ""
        ])
    else:
        report_lines.extend([
            "âŒ AUDIT Ã‰CHOUÃ‰",
            "",
            f"Nombre de divergences : {len(divergent)}",
            f"Nombre de fichiers manquants : {len(missing)}",
            "",
            "Action requise : VÃ©rifier les fichiers signalÃ©s ci-dessus.",
            ""
        ])
    
    report_lines.extend([
        "â•" * 80,
        "Fin du rapport",
        "â•" * 80
    ])
    
    return '\n'.join(report_lines)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MAIN
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def main():
    """Point d'entrÃ©e principal."""
    print("ğŸ” DÃ©marrage de l'audit cryptographique SSOT v1.0...")
    print(f"ğŸ“‚ RÃ©pertoire projet : {PROJECT_ROOT}")
    print(f"ğŸ“„ Registre des hashes : {HASHES_FILE.relative_to(PROJECT_ROOT)}")
    print()
    
    start_time = datetime.now()
    
    # Charger le registre
    print("ğŸ“– Chargement du registre des hashes...")
    registry = load_hashes_registry()
    
    # Extraire les livrables
    print("ğŸ“‹ Extraction des livrables...")
    deliverables = extract_deliverables(registry)
    print(f"   â†’ {len(deliverables)} fichiers Ã  vÃ©rifier")
    print()
    
    # VÃ©rifier les hashes
    print("ğŸ” VÃ©rification des hashes SHA256...")
    valid, divergent, missing = verify_deliverables(deliverables)
    
    # Calculer le hash global du corpus
    print("ğŸ§® Calcul du hash global du corpus...")
    corpus_hash = calculate_corpus_hash(valid)
    
    # Mesurer le temps d'exÃ©cution
    execution_time = (datetime.now() - start_time).total_seconds()
    
    # GÃ©nÃ©rer le rapport
    print("ğŸ“ GÃ©nÃ©ration du rapport...")
    report = generate_report(valid, divergent, missing, corpus_hash, execution_time)
    
    # Sauvegarder le rapport
    REPORT_FILE.parent.mkdir(parents=True, exist_ok=True)
    with open(REPORT_FILE, 'w', encoding='utf-8') as f:
        f.write(report)
    
    print(f"âœ… Rapport gÃ©nÃ©rÃ© : {REPORT_FILE.relative_to(PROJECT_ROOT)}")
    print()
    
    # Afficher le rÃ©sumÃ©
    print("â”€" * 80)
    print("RÃ‰SUMÃ‰ DE L'AUDIT")
    print("â”€" * 80)
    print(f"âœ… Fichiers valides    : {len(valid)}")
    print(f"âŒ Divergences         : {len(divergent)}")
    print(f"âš ï¸  Fichiers manquants : {len(missing)}")
    print(f"ğŸ” Hash corpus         : {corpus_hash}")
    print(f"â±ï¸  Temps d'exÃ©cution   : {execution_time:.3f}s")
    print()
    
    if divergent or missing:
        print("âŒ AUDIT Ã‰CHOUÃ‰ - Des anomalies ont Ã©tÃ© dÃ©tectÃ©es")
        return 1
    else:
        print("âœ… AUDIT RÃ‰USSI - IntÃ©gritÃ© du SSOT v1.0 confirmÃ©e")
        return 0

if __name__ == "__main__":
    sys.exit(main())
